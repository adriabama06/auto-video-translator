services:
  whisper-stt:
    ports:
      - 8881:8000
    image: ghcr.io/speaches-ai/speaches:latest-cuda-12.6.3
    restart: always
    volumes:
      - ./model_aliases.turbo.json:/home/ubuntu/speaches/model_aliases.json
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://0.0.0.0:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
  kokoro-tts:
    ports:
      - 8882:8880
    image: ghcr.io/remsky/kokoro-fastapi-gpu:v0.2.1
    restart: always
    environment:
      - DOWNLOAD_MODEL=true
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://0.0.0.0:8880/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
  indextts:
    ports:
      - 8882:8000
    image: ghcr.io/adriabama06/auto-video-translator-indextts:latest
    build:
      context: util
      dockerfile: Dockerfile.indextts.1.5
    restart: always
    volumes:
      - ./checkpoints:/app/checkpoints
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://0.0.0.0:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
  openaudio-s1-mini:
    environment:
      - HF_TOKEN=your_token_here
    ports:
      - 8882:6673
    image: ghcr.io/adriabama06/auto-video-translator-openaudio-s1-mini:latest
    build:
      context: util
      dockerfile: Dockerfile.openaudio-s1-mini
    restart: always
    volumes:
      - ./checkpoints:/opt/fish-speech/checkpoints
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
  qwen3tts:
    ports:
      - 8882:8000
    image: ghcr.io/adriabama06/auto-video-translator-qwen3tts:latest
    build:
      context: util
      dockerfile: Dockerfile.qwen3tts
    restart: always
    volumes:
      - ./checkpoints:/Qwen3-TTS/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
  libretranslate:
    image: libretranslate/libretranslate:v1.7.2-cuda
    ports:
      - "8883:5000"
    environment:
      - LT_UPDATE_MODELS=true
      - LT_LOAD_ONLY=en,es
    tty: true
    restart: always
    healthcheck:
      test: [ 'CMD-SHELL', './venv/bin/python scripts/healthcheck.py' ]
      interval: 10s
      timeout: 4s
      retries: 4
      start_period: 5s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities:
                - gpu
